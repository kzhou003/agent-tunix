

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Glossary &mdash; Agent-Tunix 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=01f34227"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Frequently Asked Questions" href="faq.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Agent-Tunix
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/configuration.html">Configuration Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/training.html">Training Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/evaluation.html">Evaluation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/experiments.html">Experiments Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Configuration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../config/overview.html">Configuration Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config/model.html">Model Configuration Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config/optimizer.html">Optimizer Configuration Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config/training.html">Training Configuration Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/train.html">Training API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/evaluate.html">Evaluation API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/models.html">Models API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/data.html">Data API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/rewards.html">Rewards API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/distributed_training.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/custom_rewards.html">Custom Reward Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/troubleshooting.html">Troubleshooting</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Glossary</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Agent-Tunix</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Glossary</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/references/glossary.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="glossary">
<h1>Glossary<a class="headerlink" href="#glossary" title="Link to this heading"></a></h1>
<dl class="simple">
<dt><strong>Accuracy</strong></dt><dd><p>Percentage of exact matches between model outputs and expected answers.</p>
</dd>
<dt><strong>Activation</strong></dt><dd><p>Output of a neural network layer; intermediate representation passed to next layer.</p>
</dd>
<dt><strong>Adaptation</strong></dt><dd><p>Process of modifying a pre-trained model for a specific task. LoRA is an adaptation technique.</p>
</dd>
<dt><strong>AdamW</strong></dt><dd><p>Adaptive Moment Estimation optimizer with decoupled weight decay. Standard optimizer used in Agent-Tunix.</p>
</dd>
<dt><strong>Attention Mask</strong></dt><dd><p>Binary mask indicating which tokens should be attended to (1) and which are padding (0).</p>
</dd>
<dt><strong>Baseline</strong></dt><dd><p>Reference value used in reward computation to normalize/center rewards.</p>
</dd>
<dt><strong>Batch Size</strong></dt><dd><p>Number of samples processed together in one training step. Larger batches = more stable gradients.</p>
</dd>
<dt><strong>Beam Search</strong></dt><dd><p>Decoding strategy that tracks multiple hypothesis sequences and keeps the best ones.</p>
</dd>
<dt><strong>Benchmark</strong></dt><dd><p>Set of standard problems used to evaluate model performance.</p>
</dd>
<dt><strong>Beta (β)</strong></dt><dd><p>In GRPO, weight controlling KL divergence penalty. Higher β keeps model closer to reference.</p>
</dd>
<dt><strong>Bias (in neural networks)</strong></dt><dd><p>Learnable parameters added to layer outputs; enables modeling non-linear relationships.</p>
</dd>
<dt><strong>Bias (statistical)</strong></dt><dd><p>Systematic errors in model predictions; different from variance.</p>
</dd>
<dt><strong>Checkpoint</strong></dt><dd><p>Saved model weights at a training step, allowing resumption and model selection.</p>
</dd>
<dt><strong>Clipping (Gradient)</strong></dt><dd><p>Limiting gradient magnitudes to prevent exploding gradients during backpropagation.</p>
</dd>
<dt><strong>Cluster Config</strong></dt><dd><p>Configuration specifying how multiple GPUs/nodes are arranged for training.</p>
</dd>
<dt><strong>Computation Graph</strong></dt><dd><p>DAG (directed acyclic graph) representing mathematical operations and their dependencies.</p>
</dd>
<dt><strong>Conditioning</strong></dt><dd><p>Process of providing context to influence model output; e.g., prompt conditioning.</p>
</dd>
<dt><strong>Configuration (Hydra)</strong></dt><dd><p>YAML-based specification of training parameters, model settings, and experiment details.</p>
</dd>
<dt><strong>Convergence</strong></dt><dd><p>Training state where loss stops decreasing, model has reached a local optimum.</p>
</dd>
<dt><strong>Cross-Entropy Loss</strong></dt><dd><p>Standard loss function for classification/language modeling tasks.</p>
</dd>
<dt><strong>CUDA</strong></dt><dd><p>Compute Unified Device Architecture; NVIDIA’s parallel computing platform for GPUs.</p>
</dd>
<dt><strong>Curriculum Learning</strong></dt><dd><p>Training strategy starting with easy examples, progressing to harder ones.</p>
</dd>
<dt><strong>Data Parallelism</strong></dt><dd><p>Distributing different data batches across multiple devices while replicating the model.</p>
</dd>
<dt><strong>Decoding</strong></dt><dd><p>Process of generating text from model logits (scores) using sampling or greedy selection.</p>
</dd>
<dt><strong>Divergence</strong></dt><dd><p>When training loss increases over time; indicates learning rate too high or data issue.</p>
</dd>
<dt><strong>Dropout</strong></dt><dd><p>Regularization technique randomly disabling neurons during training to prevent overfitting.</p>
</dd>
<dt><strong>FSDP</strong></dt><dd><p>Fully Sharded Data Parallel; JAX distributed training strategy sharding model and data.</p>
</dd>
<dt><strong>Embedding</strong></dt><dd><p>Vector representation of discrete tokens or concepts learned during training.</p>
</dd>
<dt><strong>Entropy</strong></dt><dd><p>Measure of randomness/uncertainty in a probability distribution.</p>
</dd>
<dt><strong>Epsilon (ε)</strong></dt><dd><p>In PPO/GRPO, clipping range for policy updates; controls maximum gradient step.</p>
</dd>
<dt><strong>Epoch</strong></dt><dd><p>One complete pass through the entire training dataset.</p>
</dd>
<dt><strong>Evaluation</strong></dt><dd><p>Process of assessing model performance on held-out test data using metrics.</p>
</dd>
<dt><strong>Example (training)</strong></dt><dd><p>Single data point consisting of input prompt and target output.</p>
</dd>
<dt><strong>Fine-tuning</strong></dt><dd><p>Training a pre-trained model on task-specific data; adapts general knowledge to specific task.</p>
</dd>
<dt><strong>Flax</strong></dt><dd><p>Neural network library for JAX providing layer abstractions and utilities.</p>
</dd>
<dt><strong>Forward Pass</strong></dt><dd><p>Computing network output given inputs; first stage of training step.</p>
</dd>
<dt><strong>Frozen Weights</strong></dt><dd><p>Model parameters that are not updated during training; held constant as reference.</p>
</dd>
<dt><strong>Generation (text)</strong></dt><dd><p>Process of producing new text sequences conditioned on prompt input.</p>
</dd>
<dt><strong>Gradient</strong></dt><dd><p>Direction and magnitude of loss change with respect to parameters; used to update weights.</p>
</dd>
<dt><strong>Gradient Accumulation</strong></dt><dd><p>Computing gradients over multiple mini-batches before updating weights; simulates larger batch.</p>
</dd>
<dt><strong>Gradient Descent</strong></dt><dd><p>Optimization algorithm updating parameters by moving in negative gradient direction.</p>
</dd>
<dt><strong>Greedy Decoding</strong></dt><dd><p>Selecting highest-probability token at each step; deterministic, fast generation.</p>
</dd>
<dt><strong>Group Relative Policy Optimization (GRPO)</strong></dt><dd><p>Reinforcement learning algorithm generating K responses per prompt and computing group-relative rewards.</p>
</dd>
<dt><strong>Hallucination</strong></dt><dd><p>Model generating plausible-sounding but false information not supported by training data.</p>
</dd>
<dt><strong>Hyperparameter</strong></dt><dd><p>Configuration setting controlling training dynamics (learning rate, batch size, etc.); not learned.</p>
</dd>
<dt><strong>Hydra</strong></dt><dd><p>Configuration management framework enabling YAML-based parametrization and composition.</p>
</dd>
<dt><strong>Input IDs</strong></dt><dd><p>Numeric token indices representing text input to neural network.</p>
</dd>
<dt><strong>Inference</strong></dt><dd><p>Using trained model to generate predictions on new data.</p>
</dd>
<dt><strong>Interpolation (Hydra)</strong></dt><dd><p>Referencing other config values using ${path.to.value} syntax.</p>
</dd>
<dt><strong>JAX</strong></dt><dd><p>Array computation library from Google enabling GPU-accelerated numerical computing.</p>
</dd>
<dt><strong>KL Divergence</strong></dt><dd><p>Measure of distance between two probability distributions; used to constrain policy deviation.</p>
</dd>
<dt><strong>Layer</strong></dt><dd><p>Distinct processing unit in neural network; applies transformation to input.</p>
</dd>
<dt><strong>Learning Rate</strong></dt><dd><p>Hyperparameter controlling step size in gradient descent; critical for training stability.</p>
</dd>
<dt><strong>Learning Rate Scheduler</strong></dt><dd><p>Strategy for adjusting learning rate during training (warmup, cosine decay, etc.).</p>
</dd>
<dt><strong>Log (training)</strong></dt><dd><p>Record of metrics (loss, accuracy, etc.) computed during training for monitoring progress.</p>
</dd>
<dt><strong>Logits</strong></dt><dd><p>Raw, unnormalized output scores from neural network before softmax/sampling.</p>
</dd>
<dt><strong>LoRA</strong></dt><dd><p>Low-Rank Adaptation; parameter-efficient fine-tuning adding small trainable matrices to frozen model.</p>
</dd>
<dt><strong>LoRA Rank</strong></dt><dd><p>Dimension of low-rank matrices in LoRA; higher rank = more capacity but more parameters.</p>
</dd>
<dt><strong>Loss Function</strong></dt><dd><p>Mathematical function quantifying difference between model predictions and targets; guided by gradients.</p>
</dd>
<dt><strong>Mask (in attention)</strong></dt><dd><p>Binary indicator controlling which tokens interact; prevents attending to future tokens (causal mask).</p>
</dd>
<dt><strong>Memory (GPU)</strong></dt><dd><p>High-speed storage on GPU holding model weights, activations, and gradients; limited resource.</p>
</dd>
<dt><strong>Mesh Shape</strong></dt><dd><p>Configuration specifying how devices arranged for distributed training (FSDP × TP dimensions).</p>
</dd>
<dt><strong>Metric</strong></dt><dd><p>Quantitative measure of model performance (accuracy, loss, F1, etc.).</p>
</dd>
<dt><strong>Mini-batch</strong></dt><dd><p>Small subset of data processed together; typical size 1-256 examples.</p>
</dd>
<dt><strong>Mixed Precision</strong></dt><dd><p>Training using both float32 (high precision) and float16 (lower precision) for speed/memory trade-off.</p>
</dd>
<dt><strong>Model</strong></dt><dd><p>Neural network architecture with learnable parameters (weights, biases, embeddings, etc.).</p>
</dd>
<dt><strong>Model Family</strong></dt><dd><p>Category of architectures (Gemma3, LLaMA, etc.); defines structure and behavior.</p>
</dd>
<dt><strong>Momentum</strong></dt><dd><p>Accumulation of previous gradients; helps optimization converge faster and escape local minima.</p>
</dd>
<dt><strong>Multi-run</strong></dt><dd><p>Running same experiment multiple times with different hyperparameter values (parameter sweep).</p>
</dd>
<dt><strong>NaN (Not a Number)</strong></dt><dd><p>Invalid floating-point value indicating computation failure; training becomes undefined.</p>
</dd>
<dt><strong>Normalization</strong></dt><dd><p>Rescaling values to standard range (usually 0-1 or mean 0, std 1) for stable training.</p>
</dd>
<dt><strong>Nucleus Sampling (Top-p)</strong></dt><dd><p>Decoding strategy selecting from highest-probability tokens summing to threshold p.</p>
</dd>
<dt><strong>Optimizer</strong></dt><dd><p>Algorithm updating model weights based on gradients (Adam, SGD, AdamW, etc.).</p>
</dd>
<dt><strong>Overrides (configuration)</strong></dt><dd><p>Command-line changes to config parameters without modifying YAML files.</p>
</dd>
<dt><strong>Parameter Sharing</strong></dt><dd><p>Reusing same weights across multiple positions/layers to reduce memory and improve efficiency.</p>
</dd>
<dt><strong>Perplexity</strong></dt><dd><p>Inverse probability of ground truth sequence; lower is better for language models.</p>
</dd>
<dt><strong>Policy</strong></dt><dd><p>Model trained using reinforcement learning to maximize expected reward.</p>
</dd>
<dt><strong>PPO (Proximal Policy Optimization)</strong></dt><dd><p>Reinforcement learning algorithm with clipped objective preventing large policy updates.</p>
</dd>
<dt><strong>Prompt</strong></dt><dd><p>Input text conditioning model output; text input to language model.</p>
</dd>
<dt><strong>Prompt Engineering</strong></dt><dd><p>Designing effective prompts to elicit desired model behavior.</p>
</dd>
<dt><strong>Pruning</strong></dt><dd><p>Removing small-weight connections from neural network to reduce size/computation.</p>
</dd>
<dt><strong>Quantization</strong></dt><dd><p>Reducing precision of weights/activations (float32 → int8) to save memory.</p>
</dd>
<dt><strong>Rank (LoRA)</strong></dt><dd><p>See LoRA Rank.</p>
</dd>
<dt><strong>Recall</strong></dt><dd><p>Fraction of positive examples correctly identified; useful for imbalanced problems.</p>
</dd>
<dt><strong>Reference Model</strong></dt><dd><p>Original frozen model used as baseline; policy model trained relative to reference.</p>
</dd>
<dt><strong>Regularization</strong></dt><dd><p>Technique preventing overfitting by penalizing complex models (dropout, L2, etc.).</p>
</dd>
<dt><strong>Reinforcement Learning (RL)</strong></dt><dd><p>Learning paradigm where agent optimizes behavior to maximize cumulative reward signal.</p>
</dd>
<dt><strong>Reward Function</strong></dt><dd><p>Function evaluating model responses and returning numerical score guiding training.</p>
</dd>
<dt><strong>Reward Shaping</strong></dt><dd><p>Adding intermediate signals to guide learning beyond primary reward.</p>
</dd>
<dt><strong>Sampling (decoding)</strong></dt><dd><p>Stochastic generation selecting tokens from probability distribution.</p>
</dd>
<dt><strong>Scheduler (learning rate)</strong></dt><dd><p>Strategy for adjusting learning rate during training for better convergence.</p>
</dd>
<dt><strong>Seed (random)</strong></dt><dd><p>Initial value for random number generator; same seed = reproducible randomness.</p>
</dd>
<dt><strong>Softmax</strong></dt><dd><p>Normalization function converting logits to probability distribution.</p>
</dd>
<dt><strong>Stable Training</strong></dt><dd><p>Training where loss smoothly decreases without spikes, divergence, or NaN errors.</p>
</dd>
<dt><strong>Step (training)</strong></dt><dd><p>Single gradient update; one mini-batch processed and weights updated.</p>
</dd>
<dt><strong>Temperature (sampling)</strong></dt><dd><p>Parameter controlling randomness of decoding (0 = deterministic, ∞ = uniform random).</p>
</dd>
<dt><strong>Tensor Parallel</strong></dt><dd><p>Distributing model tensors across multiple devices; suits very large models.</p>
</dd>
<dt><strong>Tokenization</strong></dt><dd><p>Process of converting text into token indices; inverse is detokenization.</p>
</dd>
<dt><strong>Token</strong></dt><dd><p>Discrete unit of text (word, subword, character); basic unit of language models.</p>
</dd>
<dt><strong>Top-k Sampling</strong></dt><dd><p>Decoding selecting from k highest-probability tokens.</p>
</dd>
<dt><strong>Training</strong></dt><dd><p>Process of updating model parameters to minimize loss on training data.</p>
</dd>
<dt><strong>Validation</strong></dt><dd><p>Evaluating model on held-out data to monitor generalization during training.</p>
</dd>
<dt><strong>Warmup (learning rate)</strong></dt><dd><p>Initial training phase with gradually increasing learning rate; improves stability.</p>
</dd>
<dt><strong>Warmup Ratio</strong></dt><dd><p>Fraction of training devoted to warmup phase (typical 0.05-0.1).</p>
</dd>
<dt><strong>Weights</strong></dt><dd><p>Learnable parameters of neural network; updated during training via gradients.</p>
</dd>
<dt><strong>Weight Decay</strong></dt><dd><p>Regularization penalizing large weights; encourages sparse solutions.</p>
</dd>
<dt><strong>Weights &amp; Biases (W&amp;B)</strong></dt><dd><p>Platform for tracking, visualizing, and comparing machine learning experiments.</p>
</dd>
<dt><strong>Zero-shot</strong></dt><dd><p>Model performing task without seeing examples; relies on pre-training knowledge.</p>
</dd>
</dl>
<section id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../guide/training.html"><span class="doc">Training Guide</span></a> - Training guide</p></li>
<li><p><a class="reference internal" href="faq.html"><span class="doc">Frequently Asked Questions</span></a> - Frequently asked questions</p></li>
<li><p><a class="reference internal" href="../getting_started/configuration.html"><span class="doc">Configuration Guide</span></a> - Configuration reference</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="faq.html" class="btn btn-neutral float-left" title="Frequently Asked Questions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Agent-Tunix Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>